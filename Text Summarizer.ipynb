{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2243,
     "status": "ok",
     "timestamp": 1623399328155,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "sH0ixwG6jTUE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1623399328156,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "NB_bth1zlrt-",
    "outputId": "77f27863-1e22-4993-954a-5c700992325a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1623399328920,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "2GuKhId7mHyf",
    "outputId": "a8960ac5-bd11-4e65-d10f-ccea176e7c57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JumpStart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74808,
     "status": "ok",
     "timestamp": 1623399403725,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "Ck5mMJtmoETu",
    "outputId": "8a27afc8-7c96-4b4a-fe8f-a99d82f1fa07"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1623399405691,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "kj-XL2kjmuNZ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/Reviews.csv',nrows=10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5ij_95cpcUv"
   },
   "source": [
    "# Drop Duplicates and NA Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1623399405692,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "GffokCEdpUgQ"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1623399406036,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "CmKUi51TpjfY",
    "outputId": "b2a215fe-0939-45f9-ea1f-54e5a2520d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 393565 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      393565 non-null  int64 \n",
      " 1   ProductId               393565 non-null  object\n",
      " 2   UserId                  393565 non-null  object\n",
      " 3   ProfileName             393565 non-null  object\n",
      " 4   HelpfulnessNumerator    393565 non-null  int64 \n",
      " 5   HelpfulnessDenominator  393565 non-null  int64 \n",
      " 6   Score                   393565 non-null  int64 \n",
      " 7   Time                    393565 non-null  int64 \n",
      " 8   Summary                 393565 non-null  object\n",
      " 9   Text                    393565 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 33.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1623399406038,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "TdiA3uW6prSl"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCF4Se-DpxGN"
   },
   "source": [
    "We will perform the below preprocessing tasks for our data:\n",
    "\n",
    "1.Convert everything to lowercase\n",
    "\n",
    "2.Remove HTML tags\n",
    "\n",
    "3.Contraction mapping\n",
    "\n",
    "4.Remove (‘s)\n",
    "\n",
    "5.Remove any text inside the parenthesis ( )\n",
    "\n",
    "6.Eliminate punctuations and special characters\n",
    "\n",
    "7.Remove stopwords\n",
    "\n",
    "8.Remove short words\n",
    "\n",
    "Let’s define the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1623399406038,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "MjTM9R2Jpy45"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 23061,
     "status": "ok",
     "timestamp": 1623399429088,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "ZBKrFUGUqpmX"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AngtNIZmrkVJ"
   },
   "source": [
    "Let us look at the first five preprocessed reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1623399429091,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "zjsvpqrAq3Zn",
    "outputId": "46a26769-cf3a-4232-c9e4-5d70605c3573"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15751,
     "status": "ok",
     "timestamp": 1623399444838,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "u205tpRTq98I"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRApDCuJrfM_"
   },
   "source": [
    "Let us look at the first 10 preprocessed summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1623399444840,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "2nKNJtqirBXe",
    "outputId": "a358da69-7c33-4cb0-c8b4-81783dcf7395"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy',\n",
       " 'nice taffy',\n",
       " 'great just as good as the expensive brands',\n",
       " 'wonderful tasty taffy',\n",
       " 'yay barley',\n",
       " 'healthy dog food']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_summary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1623399444840,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "VmkSI8sMrWU3"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zCrS7FErvDL"
   },
   "source": [
    "Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623399444841,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "v__Lh7YVr0la"
   },
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_rgF3Uar7Wk"
   },
   "source": [
    "# Understanding the distribution of the sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzYMaeAFsBCI"
   },
   "source": [
    "Here, we will analyze the length of the reviews and the summary to get an overall idea about the distribution of length of the text. This will help us fix the maximum length of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1623399445806,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "Egzglr31sCOp",
    "outputId": "aaab9793-baed-40ed-b328-14815906f1d1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLVWBrC0sOy0"
   },
   "source": [
    "\n",
    "Interesting. We can fix the maximum length of the summary to 8 since that seems to be the majority summary length.\n",
    "\n",
    "Let us understand the proportion of the length of summaries below 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1623399445807,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "WhmF6u1QsPsg",
    "outputId": "289d60a5-fb3c-4f26-e7b0-0ca59927ebb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9458130834941876\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmXSfSLssXFx"
   },
   "source": [
    "\n",
    "We observe that 94% of the summaries have length below 8. So, we can fix maximum length of summary to 8.\n",
    "\n",
    "Let us fix the maximum length of review to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623399445808,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "SeamvhT8sYZr"
   },
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JMxZWfItUZg"
   },
   "source": [
    "Let us select the reviews and summaries whose length falls below or equal to max_text_len and max_summary_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623399445808,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "E2hXo6eftS0i"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiORIna2tiQn"
   },
   "source": [
    "Here, we add START and END special tokens at the beginning and end of the summary. We have chosen sostok and eostok as START and END tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623399446127,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "Bweg-yTwthJ3"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAGZZFNPtoHi"
   },
   "source": [
    "We are getting closer to the model building part. Before that, we need to split our dataset into a training and validation set. We’ll use 90% of the dataset as the training data and evaluate the performance on the remaining 10% (holdout set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623399446128,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "QxNI7gahtpMr"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jqw3iAN0twCb"
   },
   "source": [
    "# Preparing the Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gl_YC-r9txZX"
   },
   "source": [
    "A tokenizer builds the vocabulary and converts a word sequence to an integer sequence. Go ahead and build tokenizers for text and summary:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgBFu7Got2cJ"
   },
   "source": [
    "Text Tokenizer¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1623399446791,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "W-Ei-HBnt0vf"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neEEIbucuALi"
   },
   "source": [
    "# Rarewords and its Coverage\n",
    "Let us look at the proportion rare words and its total coverage in the entire text\n",
    "\n",
    "Here, We define the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1623399446792,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "K7FMRrl5uIA1",
    "outputId": "380cb87e-8465-429c-d7f5-4f5ea809fd7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 68.11028647495395\n",
      "Total Coverage of rare words: 1.4450730144421176\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUPL0j9-uPPt"
   },
   "source": [
    "\n",
    "*   **tot_cnt** gives the size of vocabulary (which means every unique words in the text)\n",
    "\n",
    "* **cnt** gives the no. of rare words whose count falls below threshold\n",
    "\n",
    "* **tot_cnt** - cnt gives the top most common words\n",
    "\n",
    "Let us define the tokenizer with top most common words for reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1919,
     "status": "ok",
     "timestamp": 1623399448708,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "-QhyoRw3uOH7"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1623399448708,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "4cc-q_6FukDm",
    "outputId": "7986aeb4-5e84-4712-9958-76bb865c9b29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17489"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICZP8GUNun0U"
   },
   "source": [
    "# Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1623399449024,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "J2jmZs1Kur2M"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('y_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cMDzUx_utw3"
   },
   "source": [
    "\n",
    "# Rarewords and its Coverage\n",
    "Let us look at the proportion rare words and its total coverage in the entire summary\n",
    "\n",
    "Here, I we define the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1623399449025,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "qWXaJLdWuzlL",
    "outputId": "a49c07ae-889f-4d41-ee0c-c1f5b839d1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 75.99750324098527\n",
      "Total Coverage of rare words: 2.592810080219758\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAzZWWS5u6Cx"
   },
   "source": [
    "Let us define the tokenizer with top most common words for summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1623399450002,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "WD2Vnj6fu8D7"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80-R8ol6vZw6"
   },
   "source": [
    "\n",
    "Let us check whether word count of start token is equal to length of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1623399450002,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "6Hl_hGyXvVWi",
    "outputId": "d0be19fd-2891-4842-9f8e-74c00520339a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192402, 192402)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p_x89GmvmxU"
   },
   "source": [
    "Here, I we delete the rows that contain only START and END tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1623399450782,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "n_Hzr_IwvkQT"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1623399450784,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "KoC95oOJwDSA"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wc_uRRQdwTSq"
   },
   "source": [
    "# Model building\n",
    "We are finally at the model building part. \n",
    "\n",
    "**Return Sequences = True**: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
    "\n",
    "**Return State = True**: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
    "\n",
    "**Initial State:** This is used to initialize the internal states of the LSTM for the first timestep\n",
    "\n",
    "**Stacked LSTM:** Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. \n",
    "\n",
    "Here, we are building a 3 stacked LSTM for the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9576,
     "status": "ok",
     "timestamp": 1623399460357,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "7aDXW3AXwe6u",
    "outputId": "529a03e7-4b7b-401d-b5ac-ced41fdc3c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      1748900     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    500000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 5000)   3005000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,839,000\n",
      "Trainable params: 7,839,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inZs9E-byzbv"
   },
   "source": [
    "\n",
    "I am using sparse categorical cross-entropy as the loss function since it converts the integer sequence to a one-hot vector on the fly. This overcomes any memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1623399460357,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "ImIdnixoyuZG"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGjucJ1Nzc0M"
   },
   "source": [
    "Our model will stop training once the validation loss increases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1623399460358,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "Owt_2z0Dzfay"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut2NOo8Qziqe"
   },
   "source": [
    "\n",
    "We’ll train the model on a batch size of 128 and validate it on the holdout set (which is 10% of our dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1343206,
     "status": "ok",
     "timestamp": 1623400803552,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "O9Mm-BoizlcW",
    "outputId": "07528201-a8ef-4407-a20f-1334dd112ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1481/1481 [==============================] - 3036s 2s/step - loss: 2.7178 - val_loss: 2.4589\n",
      "Epoch 2/50\n",
      "1481/1481 [==============================] - 3372s 2s/step - loss: 2.3913 - val_loss: 2.2925\n",
      "Epoch 3/50\n",
      "1481/1481 [==============================] - 3388s 2s/step - loss: 2.2765 - val_loss: 2.2194\n",
      "Epoch 4/50\n",
      "1481/1481 [==============================] - 3430s 2s/step - loss: 2.2084 - val_loss: 2.1614\n",
      "Epoch 5/50\n",
      "1481/1481 [==============================] - 3387s 2s/step - loss: 2.1632 - val_loss: 2.1343\n",
      "Epoch 6/50\n",
      "1481/1481 [==============================] - 3400s 2s/step - loss: 2.1289 - val_loss: 2.1119\n",
      "Epoch 7/50\n",
      "1481/1481 [==============================] - 3368s 2s/step - loss: 2.1080 - val_loss: 2.0976\n",
      "Epoch 8/50\n",
      "1481/1481 [==============================] - 3362s 2s/step - loss: 2.0887 - val_loss: 2.0839\n",
      "Epoch 9/50\n",
      "1481/1481 [==============================] - 3366s 2s/step - loss: 2.0709 - val_loss: 2.0779\n",
      "Epoch 10/50\n",
      "1481/1481 [==============================] - 3358s 2s/step - loss: 2.0594 - val_loss: 2.0762\n",
      "Epoch 11/50\n",
      "1481/1481 [==============================] - 3340s 2s/step - loss: 2.0547 - val_loss: 2.0708\n",
      "Epoch 12/50\n",
      "1481/1481 [==============================] - 3326s 2s/step - loss: 2.0456 - val_loss: 2.0621\n",
      "Epoch 13/50\n",
      "1481/1481 [==============================] - 3341s 2s/step - loss: 2.0328 - val_loss: 2.0636\n",
      "Epoch 14/50\n",
      "1481/1481 [==============================] - 3357s 2s/step - loss: 2.0239 - val_loss: 2.0554\n",
      "Epoch 15/50\n",
      "1481/1481 [==============================] - 3343s 2s/step - loss: 2.0145 - val_loss: 2.0480\n",
      "Epoch 16/50\n",
      "1481/1481 [==============================] - 3345s 2s/step - loss: 2.0088 - val_loss: 2.0548\n",
      "Epoch 17/50\n",
      "1481/1481 [==============================] - 3348s 2s/step - loss: 1.9999 - val_loss: 2.0572\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1623400803556,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "TRYq5vxgdomP"
   },
   "outputs": [],
   "source": [
    "model.save('C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/my_model_history.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFJBcapBztzQ"
   },
   "source": [
    "# Understanding the Diagnostic plot\n",
    "Now, we will plot a few diagnostic plots to understand the behavior of the model over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 8203,
     "status": "ok",
     "timestamp": 1623400811744,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "cBORU65Lz0oS",
    "outputId": "758f2a7b-1516-4c14-bc43-2b198f9f3c64"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAusUlEQVR4nO3deXyU5b3//9dnksm+L4SQhQCyIwmrWFvcqqK1LnWptVpbT0vrt6c/22+1Vc9Pv/V0OT2n/Vlt+7UeqlatVutR1FqxCoriAlrAIEvY15AQQsi+L5/fH/cEQsgyAzOZzOTzfDzmkWHu+5r5hOXNneu67usSVcUYY0zocwW7AGOMMf5hgW6MMWHCAt0YY8KEBboxxoQJC3RjjAkTkcH64IyMDC0oKAjWxxtjTEhat27dEVXN7OtY0AK9oKCAtWvXBuvjjTEmJInIvv6OWZeLMcaECQt0Y4wJExboxhgTJoLWh26MMaeivb2d0tJSWlpagl1KQMXExJCbm4vb7fa6jQW6MSaklJaWkpiYSEFBASIS7HICQlWpqqqitLSUcePGed3OulyMMSGlpaWF9PT0sA1zABEhPT3d559CLNCNMSEnnMO826l8jyEX6NsO1fOLZSU0tXUEuxRjjBlWQi7QS6ubWLJqN5sO1gW7FGPMCFRTU8PDDz/sc7vLLruMmpoa/xfUQ8gF+szcFAA2HKgJah3GmJGpv0Dv7OwcsN2yZctISUkJUFWOQQNdRPJEZKWIlIjIZhG5vY9z7hSRYs9jk4h0ikhaIArOTIwmJyWW4tKaQLy9McYM6K677mLXrl0UFRUxb948zj//fG688UbOPPNMAK666irmzJnD9OnTWbJkybF2BQUFHDlyhL179zJ16lS+9a1vMX36dC6++GKam5v9Ups30xY7gB+q6noRSQTWichyVd3SfYKq/gr4FYCIfBH4gaoe9UuFfSjKS7ErdGMM97+6mS1l/u1+nTYmif/zxen9Hv/lL3/Jpk2bKC4u5p133uELX/gCmzZtOja98PHHHyctLY3m5mbmzZvHNddcQ3p6+gnvsWPHDp599ln++Mc/cv311/Piiy9y0003nXbtg16hq2q5qq73PK8HSoCcAZp8BXj2tCsbQGFeMqXVzRxpaA3kxxhjzKDmz59/wlzx3/72txQWFrJgwQIOHDjAjh07Tmozbtw4ioqKAJgzZw579+71Sy0+3VgkIgXALOCjfo7HAYuAf+3n+GJgMUB+fr4vH32CorxUAD4treGCKVmn/D7GmNA20JX0UImPjz/2/J133mHFihWsXr2auLg4zjvvvD7nkkdHRx97HhER4bcuF68HRUUkAXgR+L6q9vczzheBD/rrblHVJao6V1XnZmb2uZyvV2bkJOESKN5fc8rvYYwxpyIxMZH6+vo+j9XW1pKamkpcXBxbt25lzZo1Q1qbV1foIuLGCfNnVHXpAKfeQIC7WwDioiKZlJVIcWltoD/KGGNOkJ6ezjnnnMOMGTOIjY0lK+t4L8GiRYt45JFHmDlzJpMnT2bBggVDWtuggS7O7UqPASWq+sAA5yUD5wKn37PvhaK8FF7fdAhVHRF3jRljho+//OUvfb4eHR3N66+/3uex7n7yjIwMNm3adOz1O+64w291edPlcg5wM3BBj6mJl4nId0TkOz3Ouxp4U1Ub/VbdAArzUqhtbmdfVdNQfJwxxgx7g16hq+r7wKCXwKr6BPDE6ZfkncLuG4xKayjIiB/4ZGOMGQFC7k7RbpOyEoh1R1Bs89GNMQYI4UCPjHBxZk6yBboxxniEbKCDc4PR5rI62jq6gl2KMcYEXYgHegptHV1sO9T3nFBjjBlJQjvQPQOjtlCXMWaonOryuQAPPvggTU2Bm5kX0oGemxpLenyULdRljBkywznQQ3qTaBGhKC/FBkaNMUOm5/K5F110EaNGjeL555+ntbWVq6++mvvvv5/Gxkauv/56SktL6ezs5N5776WiooKysjLOP/98MjIyWLlypd9rC+lAB6cf/e1th6lraScpxh3scowxQ+n1u+DQRv++5+gz4dJf9nu45/K5b775Ji+88AIff/wxqsoVV1zBqlWrqKysZMyYMbz22muAs8ZLcnIyDzzwACtXriQjI8O/NXuEdJcLOIGuCptsXRdjzBB78803efPNN5k1axazZ89m69at7NixgzPPPJMVK1bw4x//mPfee4/k5OQhqSf0r9Bznd+o4tIaPnNGYP7XM8YMUwNcSQ8FVeXuu+/m29/+9knH1q1bx7Jly7j77ru5+OKLue+++wJeT8hfoafERVGQHmcDo8aYIdFz+dxLLrmExx9/nIaGBgAOHjzI4cOHKSsrIy4ujptuuok77riD9evXn9Q2EEL+Ch2clRfX7A7YjnfGGHNMz+VzL730Um688UbOPvtsABISEnj66afZuXMnd955Jy6XC7fbzR/+8AcAFi9ezKWXXkp2dnZABkVFVf3+pt6YO3eurl271i/v9acP9nD/q1tYc/eFjE6O8ct7GmOGp5KSEqZOnRrsMoZEX9+riKxT1bl9nR/yXS7gDIwCNn3RGDOihUWgT8tOItIlbLA7Ro0xI1hYBHqMO4Kp2Uk2MGrMCBGsruKhdCrfY1gEOjgrL35aWktXV/j/QRszksXExFBVVRXWoa6qVFVVERPj25hgWMxyASjKS+XpNfvZfaSBM0YlBrscY0yA5ObmUlpaSmVlZbBLCaiYmBhyc3N9ahNGge7cYPTJ/hoLdGPCmNvtZty4ccEuY1gatMtFRPJEZKWIlIjIZhG5vZ/zzvNsIL1ZRN71f6kDG5+RQEJ0pA2MGmNGLG+u0DuAH6rqehFJBNaJyHJV3dJ9goikAA8Di1R1v4iMCky5/XO5hJm5yWw4YGu6GGNGpkGv0FW1XFXXe57XAyVATq/TbgSWqup+z3mH/V2oNwrzUigpr6OlvTMYH2+MMUHl0ywXESkAZgEf9To0CUgVkXdEZJ2IfK2f9otFZK2IrA3EgEZhbgodXcqW8jq/v7cxxgx3Xge6iCQALwLfV9XeiRkJzAG+AFwC3Csik3q/h6ouUdW5qjo3MzPzNMru26z8FACbj26MGZG8muUiIm6cMH9GVZf2cUopcERVG4FGEVkFFALb/VapF7KSYhidFGNLABhjRiRvZrkI8BhQoqoP9HPaK8DnRCRSROKAs3D62odcYV6yXaEbY0Ykb67QzwFuBjaKSLHntXuAfABVfURVS0TkH8CnQBfwqKpuCkC9gyrMS+GNzRXUNLWREhcVjBKMMSYoBg10VX0fEC/O+xXwK38UdTqKclMA2FBay7mT/N9Pb4wxw1XYrOXS7czcZERsYNQYM/KEXaAnxrg5IzPBAt0YM+KEXaCD049efKAmrFdjM8aY3sI20Ksa2yitbg52KcYYM2TCMtCPD4zWBLUOY4wZSmEZ6JNHJxIV6bJ+dGPMiBKWgR4V6WLGmCRbedEYM6KEZaCD04++8WAtHZ1dwS7FGGOGRNgGelFeCs3tnWyvaAh2KcYYMyTCNtALbWDUGDPChG2gj02PIznWbQOjxpgRI2wDXUSO3WBkjDEjQdgGOjj96Nsr6mlq6wh2KcYYE3BhHujJdClsLLXpi8aY8BfWgT7TBkaNMSNIWAd6RkI0uamxdoORMWZECOtAB2xg1BgzYoR9oBflpnCwppnK+tZgl2KMMQHlzSbReSKyUkRKRGSziNzexznniUitiBR7HvcFplzfFeWnAPCp9aMbY8KcN5tEdwA/VNX1IpIIrBOR5aq6pdd576nq5f4v8fRMH5NEhEsoPlDDhVOzgl2OMcYEzKBX6KparqrrPc/rgRIgJ9CF+UtcVCSTshKtH90YE/Z86kMXkQJgFvBRH4fPFpENIvK6iEzvp/1iEVkrImsrKyt9r/YUFeUls8G2pDPGhDmvA11EEoAXge+ral2vw+uBsapaCPwOeLmv91DVJao6V1XnZmZmnmLJvivMTaGupYO9VU1D9pnGGDPUvAp0EXHjhPkzqrq093FVrVPVBs/zZYBbRDL8Wulp6B4YtYW6jDHhzJtZLgI8BpSo6gP9nDPacx4iMt/zvlX+LPR0TByVSFxUhPWjG2PCmjezXM4BbgY2ikix57V7gHwAVX0EuBa4TUQ6gGbgBh1GHdYRLmFGTrIFujEmrA0a6Kr6PiCDnPN74Pf+KioQivJSeOKDvbR1dBEVGfb3UxljRqARk2yFuSm0dXax9VDv8VxjjAkPIyfQ85IBGxg1xoSvERPoOSmxZCREU2wrLxpjwtSICXQRcW4wsjVdjDFhKvQCvbMDdq6AU5hEU5ibwq7KBupa2gNQmDHGBFfoBfqGv8DT10DpWp+bFualoLYlnTEmTIVeoE+/GqIS4Z+P+tx0Zq4zMGrz0Y0x4Sj0Aj06EQpvgM1LofGIT01T4qIYlxFvM12MMWEp9AIdYN43obMNPvmzz02L8lJsYNQYE5ZCM9BHTYGCz8Hax6Gr06emhbnJVNS1cqi2JUDFGWNMcIRmoAPM+xeo2Q87lvvUrDAvBYDiA9UBKMoYY4IndAN9yuWQMNrnwdGp2Um4I8RuMDLGhJ3QDfQIN8z5ujMn/ehur5vFuCOYmp1kA6PGmLATuoEOMOcWEBes/ZNPzQpzU9h4sJbOrmGzwq8xxpy20A70pDEw5QvObJf2Zq+bFeWl0NDawe7KhgAWZ4wxQyu0Ax1g/reguRo2v+R1k+6B0U+s28UYE0ZCP9ALPgcZk3waHB2fEU9idKT1oxtjwkroB7qIc6PRwXVwcL1XTVwuYaatvGiMCTOhH+jgLAXgjod/PuZ9k9wUtpbX09Lu241JxhgzXA0a6CKSJyIrRaRERDaLyO0DnDtPRDpF5Fr/ljmImGSYeT1segGajnrVpCgvhY4uZXOZbUlnjAkP3lyhdwA/VNWpwALguyIyrfdJIhIB/Cfwhn9L9NK8b0JHCxQ/49XpRZ6BUetHN8aEi0EDXVXLVXW953k9UALk9HHq94AXgcN+rdBbo2dA/tlOt0tX16Cnj0qKITs5xpbSNcaEDZ/60EWkAJgFfNTr9RzgauCRQdovFpG1IrK2srLSx1K9MO+bUL0Hdr/t1emFubbyojEmfHgd6CKSgHMF/n1V7d3x/CDwY1UdcIRRVZeo6lxVnZuZmelzsYOa+kWIz4SPvZvCWJiXwr6qJo42tvm/FmOMGWJeBbqIuHHC/BlVXdrHKXOB50RkL3At8LCIXOWvIr0WGQ2zb4Ht/4DqfYOe/rmJGQAsWeX9WjDGGDNceTPLRYDHgBJVfaCvc1R1nKoWqGoB8ALwv1T1ZX8W6rU5X3fmpq97YtBTZ+Qkc+2cXB59bzc7D9cHvDRjjAkkb67QzwFuBi4QkWLP4zIR+Y6IfCfA9fkuJQ8mXQrrn4KO1kFPv+vSKcRGRfB//rYZVVusyxgTuiIHO0FV3wfE2zdU1a+fTkF+Mf+bsO012PKKMz99ABkJ0dx5yWTue2Uzr20s5/KZY4aoSGOM8a/wuFO0t3HnQdoEr9d3+epZY5k+Jomf/b2ExtaOgJZmjDGBEp6B7nI5W9Qd+AjKPx309AiX8O9XzuBQXQu/fXvHEBRojDH+F56BDlB0I0TGen2VPmdsKtfPzeWx9/bYAKkxJiSFb6DHpsKZ18LG/4HmGq+a/HjRFOKiIrjvFRsgNcaEnvANdHDuHG1vgg3PeXV6ekI0dy6awoe7qvj7p+UBLs4YY/wrvAN9TBHkzHW6Xby84r5xfj4zcpL42WtbaLABUmNMCAnvQAdni7qqHbDnXa9Oj3AJP71yBhV1rfz2LRsgNcaEjvAP9GlXQWyaT1vUzcpP5YZ5eTz+/h62V9gAqTEmNIR/oLtjYPbNsHUZ1B70utmPFk0hPjqS+17ZZAOkxpiQEP6BDjD3VtAur9Z36ZYWH8WPFk1mze6j/G1DWeBqM8YYPxkZgZ5aABMvhvVPQof3S+XeMC+fmbnJ/Py1Eupb2gNXnzHG+MHICHRwpjA2VMDWv3vdpHuAtLKhlYdW2ACpMWZ4GzmBfsbnIWWsT4Oj4GyCccO8fP704V62HbIBUmPM8DVyAr17fZd9H0DFFp+a/uiSySTGRHKvDZAaY4axkRPoAEU3QUQ0rH3Mp2ap8VH8eNEUPt5zlFeKbYDUGDM8jaxAj0+HGdc4SwG09N4WdWBfnptHYV4KP19WQp0NkBpjhqGRFejgDI62NcCnf/Wpmcsl/PTK6RxpaOXB5TZAaowZfkZeoOfMhuwi+OdjXq/v0m1mbgo3zs/nydV7KSn37QrfGGMCzZtNovNEZKWIlIjIZhG5vY9zrhSRTz37ja4Vkc8Gplw/EHGu0itLnAFSH915yWSSYuwOUmPM8OPNFXoH8ENVnQosAL4rItN6nfMWUKiqRcCtgG9zA4fajGsgJsXnKYwAKXFR3HXpFP65t5qXPvF+KQFjjAm0QQNdVctVdb3neT1QAuT0OqdBj1+uxgPD+9I1Kg5m3QQlr0L9IZ+bXzcnj6K8FH6xrITaZhsgNcYMDz71oYtIATAL+KiPY1eLyFbgNZyr9L7aL/Z0yaytrKw8hXL9aO6t0NUB65/yuanLJfzsqhlUNbbxm+XbA1CcMcb4zutAF5EE4EXg+6p60oigqr6kqlOAq4Cf9vUeqrpEVeeq6tzMzMxTLNlP0ifAhAth7Z+g0/er7Bk5ydx01lieWr2XLWU2QGqMCT6vAl1E3Dhh/oyqLh3oXFVdBUwQkQw/1BdYC26D+jJ49Xbo6vK5+R0XTyYlLor7XtlEV9fw7mUyxoQ/b2a5CPAYUKKqD/Rzzhme8xCR2UAUUOXPQgNi4kVw3t1Q/Az84y6fpzEmx7m569IprN1XzVIbIDXGBFmkF+ecA9wMbBSRYs9r9wD5AKr6CHAN8DURaQeagS9rqMzpO/fH0FoPq38P0Ylw4b0+Nb92di7Pfbyf/1hWwkXTskiOdQeoUGOMGdigga6q7wMyyDn/Cfynv4oaUiJw8c+gtQ7e+zVEJ8Bnf+B1c5dL+PcrZ3DF79/ngTe3cf+VMwJYrDHG9G/k3SnaFxG4/EFnfvqKn8DHf/Sp+YycZG5eMJY/r9nH21srAlKiMcYMxgK9mysCrv5vmHQpLLvDWcDLB3dcMpnpY5L59p/XsWKLhboxZuhZoPcU4YbrnoBxC+Hl/+XceOSlxBg3T3/zLKaNSea2Z9bxj02+37BkjDGnwwK9N3cM3PCss4jXC7fCzre8bpoc6+bP/zKfGTnJ/Otf1rNsY3kACzXGmBNZoPclOgG++j+QMQme+yrsX+N106QYN0/dOp+ivBS+9+wnvLrBNsQwxgwNC/T+xKbCzS9Bcg48cx2UFXvdNDHGzZO3zmfO2FRuf+4TXim2OerGmMCzQB9Iwii4+WWISYanvwSV27xuGh8dyRPfmMdZ49L5wV+LeXFdaeDqNMYYLNAHl5IHX3sFJAKeuhKq93rdNC4qkse/Po/PTMjgjhc28Pw/DwSuTmPMiGeB7o30CfC1l6G9GZ68Auq87xePjYrg0Vvm8tkzMvjRi5/yl4/2B65OY8yIZoHurazpcNNSaKqCp66CRu+XqolxR/DHr83lvMmZ3PPSRv68Zl/g6jTGjFgW6L7InQNfeQ5q9sHTV0NLrddNY9wR/PfNc7hwyijufXkTT3ywJ4CFGmNGIgt0X437HFz/Z6jYDM9cD22NXjeNjozgDzfN4aJpWfzk1S08+t7uABZqjBlpLNBPxaSL4ZpHofRj+OtN0NHqddOoSBcPf3U2l84Yzc9eK2HJql0BLNQYM5JYoJ+q6VfDF38Lu9527ijt7PC6qTvCxW+/MosvzMzmF8u28vA7OwNYqDFmpPBmPXTTn9k3Q1uDsznGK9+Fq/4ALu/+j3RHuHjoy0VEiPBf/9hGZ6fyvQsnBrhgY0w4s0A/XQtuczbIWPlzZ8mAy37tLMfrhcgIF7/5chGRLuH/W76dji7l+5+fiHjZ3hhjerJA94eFdzobZHz4O2ipgyt+5yzy5YUIl/Cr6wpxuYSH3tpBlyr/+6JJFurGGJ9ZoPuDCFz0U2eJgLd/5txNesMzztIBXohwCf91zUwiXcLv3t5JR5fyo0smW6gbY3xig6L+IuJcqV/3JBzaCH+8wJna6CWXS/jF1Wdy41n5/OGdXfzH61sJlW1ZjTHDw6CBLiJ5IrJSREpEZLOI3N7HOV8VkU89jw9FpDAw5YaA6VfBN5ZBVwc8djFsf8Prpi6X8POrZvC1s8eyZNVubnrsIw4cbQpcrcaYsOLNFXoH8ENVnQosAL4rItN6nbMHOFdVZwI/BZb4t8wQkzMbvvW2swbMszfA6v8LXl5tiwj3XzGdn101gw0Harn4N6t44oM9dHXZ1boxZmCDBrqqlqvqes/zeqAEyOl1zoeqWu355Rog19+FhpykMfCN12HKF+CNe+DV26Gz3aumIsJNC8byxg8WMn9cGj95dQvX//dqdlc2BLhoY0wo86kPXUQKgFnARwOc9i/A6/20Xywia0VkbWVlpS8fHZqi4uG6p+BzP4T1T8Kfr4amo143z0mJ5YlvzOPX1xWyvaKeRQ+9xyPv7qKjsyuARRtjQpV4O/AmIgnAu8DPVXVpP+ecDzwMfFZVB1yOcO7cubp27Vofyw1hG56Dv30PkvPgxuch4wyfmh+ua+H/fXkTb26pYGZuMv917UymjE4KULHGmOFKRNap6ty+jnl1hS4ibuBF4JkBwnwm8Chw5WBhPiIV3gC3vAotNfDoBbD7HZ+aj0qK4b9vnsPvb5zFwepmvvi793loxQ7aOuxq3Rjj8GaWiwCPASWq+kA/5+QDS4GbVXW7f0sMI/kLnMHSxDHw5y/B2sd9ai4iXD5zDMv/97lcdmY2v1mxnSt+/z4bS71fxtcYE74G7XIRkc8C7wEbge7LwXuAfABVfUREHgWuAbp3bujo70eCbiOuy6WnljpnQa+dy+Gs2+CSn4Mrwue3Wb6lgn97aSNVjW0sXjie2y+cSIzb9/cxxoSOgbpcvO5D97cRHejgrM64/F5Y8zCccRFc+zjE+N4nXtvczi9eK+Gvaw8wPjOeX107kzlj0wJQsDFmODjtPnQTABGRsOg/4PLfOEvwPnaxTxtQd0uOdfOf187kqVvn09rexbWPrOb+VzfT1Ob9cr7GmPBggR5sc2+Fm5dCfRn88ULYv+aU3mbhpEze+MFCbl4wlj99sJdFD77HhzuP+LlYY8xwZoE+HIw/D775lrO415NfdKY4noKE6Ej+/coZ/HXxAlwCNz76Efe8tJH6Fu9uaDLGhDYL9OEiYyJ8cwXknQUvfRtW3A/tLaf0VmeNT+f12xeyeOF4nvt4Pxf/ZhXP//MA7XZDkjFhzQZFh5vOdnjNc2dpTIozf332LZDVe/kc7xQfqOHelzex8WAteWmxfPe8M/jS7FyiIu3/cmNCkc1yCTWqsGcVrHsCtv4dOtsgZy7MuQWmf8nZGcmnt1NWbjvMQyt2sKG0lpyUWL57/hlcO8eC3ZhQY4Eeyhqr4NPnYN2TcGQbRCXAjGucq/ac2V5vdwdOsL+zvZKHVuyg+EANOSmx3HbeBK6bm0t0pM1fNyYUWKCHA1U48LHTFbNpKXQ0Q9YMJ9hnXgexqT68lbJqxxEeXLGdT/bXMCY5htvOm8D18/Is2I0Z5izQw01LLWx8AdY/BeXFEBkD066E2V+Dsed4fdWuqry34wgPvbWDdfuqGZ3kBPuX5+XZHafGDFMW6OGsfIPTHbPxf5yNqtPPcIK98Cte72mqqnyws4qH3trOP/dWk5UUzW3nTuCG+fkW7MYMMxboI0FbE2x52blq378aXJEw+TKnS2bC+V6tFaOqrN5VxYNv7eDjPUcZlRjNd86dwI1nWbAbM1xYoI80lducYC/+CzQfddZgn3al88iZC67BZ7as3uVcsa/ZfZTMxGi+vXA8Xz1rLLFRFuzGBJMF+kjV0QpbX3OCffc70NXuLN079XKYegWM/cygV+4f7a7iobd28OGuKjISolm8cBxXzcphVGLM0HwPxpgTWKAbaK6B7W9Ayd9g5wroaIG4DGfP02lXQMFCiIzqt/nHe47y0Fvb+WCns3dJYV4Kn58yigunZjE1OxHxYfqkMebUWaCbE7U1wo7lTrhvfwPaGpx1ZCZd6oT7hAvAHdtn062H6lixpYLlJYfZcKAGcPY+vXCqE+4LxqfZ1EdjAsgC3fSvvQV2r4SSV53umZYacMfDpIudbpmJF/d7Z+rh+hZWbj3MipLDvL/jCM3tncRHRbBwUiYXTs3i/MmZpCdED+33Y0yYs0A33ulsh73vwZa/OUsONFZCRDSccaET7pMX9XsDU0t7Jx/uOsKKksO8VVJBRV0rIjA7P5ULp47i81OzmDgqwbpmjDlNFujGd12dcOAjJ9xLXoW6Umcq5LiFkH82jJntLD0Qd/LuSKrK5rI6VpRUsKKkgk0H6wDIT4s7Fu7zx6XhjrB1ZIzx1WkFuojkAU8Bo3H2FF2iqg/1OmcK8CdgNvBvqvrrwYqyQA8hqnBwPZS8Atv+4awp0y1lrBPsY2Y5IT+mCKITT2h+qLaFt7ZW8FbJYT7YeYTWji4SoyNZODmT8yePYuGkDJs1Y4yXTjfQs4FsVV0vIonAOuAqVd3S45xRwFjgKqDaAj3MtdQ5Sw4cXA9l6+HgJ1C733NQIGOSJ+Q9V/FZM8DtBHZTWwfv7zjCWyWHeXvbYSrrWwGYlp3EwkmZnDspkzljU20VSGP64dcuFxF5Bfi9qi7v49hPgAYL9BGo8QiUfdIj5NdD42HnmCsSRk07MeQzp9IlEZQcquPd7ZWs2l7J2r3VdHQp8VERnD0hg3MnZ3LepEzy0uKC+70ZM4z4LdBFpABYBcxQ1bo+jv+EAQJdRBYDiwHy8/Pn7Nu3z+vPNiFGFerKjod72Xon8FtqneORsTD6TE9XTRFkF9KQNIEPd9ewakcl72yrpLS6GYDxGfHHrt4XjE+3u1XNiOaXQBeRBOBd4OequrSfc36CXaGb/qjC0d0nXsmXfwrtjc7xyFgYPQOyi9DsQg7GTmbFkVTe3VnN6t1VtLR3ERXpYn5BGudOyuTcyZk2c8aMOKcd6CLiBv4OvKGqDwxw3k+wQDe+6OqEqp1QVuz0y5cVw6FPnZudwFkaOGsGHaML2e0+g3frxrC0NJGSw85+q9nJMSycmMnCSZl8ZkI6qfH93+1qTDgYKNAjvWgswGNAyUBhbswpcUVA5mTnUfhl57WuLji664SQj9z4PJPa6pkEfCsimraxU9kXPYmPmvN4ZdMolq7NpkMimTo6ic9MSOczZ6QzryCNxBh3EL85Y4aWN7NcPgu8B2zEmbYIcA+QD6Cqj4jIaGAtkOQ5pwGY1lc/eze7Qjc+6epyumvKi50um/INzqPV+SvW5XLT6E6jsiuJA63xVGoSVSQTlZRF5ugcCvILOGP8eGKSsyA+AyIs6E1oshuLTHjq6oLqPU7AV2yC+gporKSroZL2ugoimo8Qqe19Nu2ISiYiMQtJyHQCPj4T4kd5nmeAO84J/Ygoz6Pn875ec/u0v6sxp+q0ulyMGbZcLkif4DzOvPb4y0A0OIOwrXU0Vh9i267d7Nm7h0PlpbTWVpDRUcuo1joKGurIijhIYkc1kW21p1dPf+EfmwJx6T0eac5Klye8lu6c58VGJMb0xwLdhC8RiEkmPjuZ2dmTmf1Z5+XapnbW7Kli9a4qfrOrim0V9QCkRsMF+S7OyYaJaVHkJ0eQHKXOGjedbZ5H9/PWfl5vd9ahP/a8xVnwrKECDpdAUxW0N/VXsLNWzknh3+PXyTnO3bnJudZtZE5iXS5mxKusb2XN7io+3FXF6l1H2Ft1PHDT46OYmJXApKxEJmYlMnGU8zztdGbTtDU5O0k1VXkePZ9Xnfx64xFnc5KexOVsVpKS7zxSxx5/npIPSTkW+GHK+tCN8UFFXQvbDtWzvaKeHRUNbD/sfG1o7Th2TkZCFBNHJTIpK4GJWYlMynKep8QFYNqkqjONs7ESakuhZv+Jj+p9UF8G2nW8jbicUE/pFfTd4Z84BiIinWmj3T9ddHUc/8miq93zeh/Hjh1vg84O53lcBqTkOT859FrLx/iXBboxp0lVKa9tYcfhBnZUOGG/vaKBnYdPDPrMxOhjV/ETsxKYOCqRzMRokmPdJMVEEhmoFSY72qDuYI+g33di6NeVAT3+rYunjp7/CfhLTDIk5zvh3h3yybnHX0vI8mpfW9M3C3RjAkRVKatt8VzNd1/RN7Czop7Gts6Tzk+IjiQ51n3SIyXOTVIfr3U/T4xxE+E6jVk0HW1Qe+B4wNeWAgout2cQ1zOQ64rsMbDr9hyPcq7mjz3vdczlcrqFut+3ttT5rNpSqDkArb0Gm11uZywgOc/z6Bn8eZA0BqLiT/17DSRVZ1ykvbnX1xboaPb+64QLnd3BToHNcjEmQESEnJRYclJiOX/yqGOvd3UpZbXN7DzcwNHGNmqb2098NDlfd1U2HHuttaP/q2URSIyOZExKLHlpceT3eOSlxZKbGkeMe4AZMpFRx2cEBULaeMib3/exllqoPegJ+R5BX1sKe1ad3F0EzlV+4hgn3JOyne6jxGzPr8c4x+LS/DNVtK0JGg450177/VrhdHt1tJz657gineUt3DHOf14BYIFuTAC4XEJuahy5qd6vFNnS3tln6Nc2t1PT3E5NUxtlNc3sq2rkvR2VtLSfGIJZSdFOwKfGHQv97q+jEqNxnc4V/umISXYeWdP6Pt7ZDvXlx4O+7qDz67oy53F4C9Qf4oQuI3B200rKPjH4jz0fA4mjBw/rhsPHbk47gSvS6RpKyHLGHfLmOWMD3YF8Kl8jAh+31uViTAhSVY40tLH/aBMHjjad9LW8roWe/7SjIl3kpZ54dT8xK5Fp2UlkJobAvq+dHc5Vcl2Zc0Vf1+PRM/w7Wwd+H3ecE9KJo48HdmIWJIzu8XU0xKYN235+63IxJsyICJmJ0WQmRjNn7Mn7vLZ2dHKwupkD1c3Hw76qiQPVTazbW039CTN2opk2Jomp2U7AT8tOYlxGfOAGcE9FRKSn3z2n/3NUobnaucKvK3eCPir+xACPTgzrO3ot0I0JQ9GREYzPTGB8ZsJJx1SV6qZ2th6qo6S8ni1ldZSU1/H4riO0d6qnvYvJoxOZOjrJE/ZJTMlOJGk4L3Ym4rkRK81Za38Esi4XYwwAbR1d7KpsoKS8zgn5Q87X6qbjNzXlpcUyLdsJ+O6vuamxtib9ELIuF2PMoKIiXUz1hPSXZjuvqSoVda1OyHseJWV1vLml4lgffWJMJOMy4slLjSM3LZa81OMDsjkpsbY/7BCyQDfG9EtEGJ0cw+jkGM6fcnxaZlNbB1sP1VNSXsfW8nr2VjWypbyO5VsqaOvs6tEeRifFHAv7nrNw8tJiyUqMCd7smzBkgW6M8VlcVCSz81OZnX/igGxXl1JR3+IZgG3mwFFnILb0aDOrd1Xx0icHT5x9E+EiJzWW3NTYE6ZZ5qfFMTY9zjYo8ZEFujHGb1wuITs5luzkWM7q43jP2TfdYX/gaBMHjjaz8WA5NU0nLkKWFh9FXlocYz0B7wR9PGPT48hMCOLc+mHKAt0YM2QGmn0DUNfSzv4qZz79/qNN7KtqYv/RRtbvr+bvn5bR1ePqPsbtIi+1O+idkM9Pd8I/JzWW6MiRt7a8BboxZthIinEzIyeZGTnJJx1r6+jiYI0zr35/VSP7qprY55lf/8HOKprbj6+dIwJjkmPJTIwmPT6KtPgo0hKiPM97vBYfRXpCFHFR4RGF4fFdGGPCXlSki3EZ8YzLiAcyTzimqlQ2tLK/qulY0B842kRlfStltS1sKqvlaGPbsXn2vcW4XaTHRx8P+T7+E8hOjiEvLY7k2OHbrz9ooItIHvAUMBpnA+glqvpQr3MEeAi4DGgCvq6q6/1frjHGnExEGJUYw6jEGOYWpPV5jqpS39rB0YY2qhrbONrYxtHGVqoa26hu7Pla27FF1Xpe9XdLiol0ZumkxpHrWU4hzzNdMzc1jtio4HX1eHOF3gH8UFXXi0gisE5Elqvqlh7nXApM9DzOAv7g+WqMMcOCiJAU4yYpxk1BhnfL8za3dVLV2EpVg7MwmjOI20xpdRM7KxtYue3wSatkZiREHwv4nkGflxbLmJRY3AFcUmHQQFfVcqDc87xeREqAHKBnoF8JPKXObadrRCRFRLI9bY0xJiTFRkWQG+UEcmFeyknHu7t6ukO+e8ZOaU0TxQdqWLaxnI4eI7kugezkWL5xTgHf/Nx4v9frUx+6iBQAs4CPeh3KAQ70+HWp57UTAl1EFgOLAfLz830s1RhjhpeeXT19LZLW0dnFoboWDhxt9szHb6K0ujlgK1x6HegikgC8CHxfVXsvINzXZNCTRh9UdQmwBJy1XHyo0xhjQk5khOvYuvhnkx7wz/OqM0dE3Dhh/oyqLu3jlFIgr8evc4Gy0y/PGGOMtwYNdM8MlseAElV9oJ/T/gZ8TRwLgFrrPzfGmKHlTZfLOcDNwEYRKfa8dg+QD6CqjwDLcKYs7sSZtvgNv1dqjDFmQN7McnmfvvvIe56jwHf9VZQxxhjf2ULFxhgTJizQjTEmTFigG2NMmLBAN8aYMBG0TaJFpBLYd4rNM4AjfizHX4ZrXTB8a7O6fGN1+SYc6xqrqpl9HQhaoJ8OEVnb367XwTRc64LhW5vV5RuryzcjrS7rcjHGmDBhgW6MMWEiVAN9SbAL6MdwrQuGb21Wl2+sLt+MqLpCsg/dGGPMyUL1Ct0YY0wvFujGGBMmQi7QRWSRiGwTkZ0iclew6wFnI20RWSkiJSKyWURuD3ZNPYlIhIh8IiJ/D3Yt3TzbFL4gIls9v29nB7smABH5gefPcJOIPCsiMUGq43EROSwim3q8liYiy0Vkh+fryVvkBKeuX3n+HD8VkZdEJGU41NXj2B0ioiKSMdR1DVSbiHzPk2WbReS//PFZIRXoIhIB/F+cTamnAV8RkWnBrQo4vpH2VGAB8N1hUle324GSYBfRy0PAP1R1ClDIMKhPRHKA/weYq6ozgAjghiCV8wSwqNdrdwFvqepE4C3Pr4faE5xc13JghqrOBLYDdw91UfRdFyKSB1wE7B/qgnp4gl61icj5OHsxz1TV6cCv/fFBIRXowHxgp6ruVtU24Dmc35SgUtVyVV3veV6PE045wa3KISK5wBeAR4NdSzcRSQIW4mycgqq2qWpNUIs6LhKIFZFIII4g7bylqquAo71evhJ40vP8SeCqoawJ+q5LVd9U1Q7PL9fg7FgW9Lo8fgP8iD62xBwq/dR2G/BLVW31nHPYH58VaoHe32bUw8YAG2kHy4M4f6G7glxHT+OBSuBPnq6gR0UkPthFqepBnCul/TgbnNeq6pvBreoEWd07gXm+jgpyPX25FXg92EUAiMgVwEFV3RDsWvowCficiHwkIu+KyDx/vGmoBbpXm1EHyyAbaQejnsuBw6q6Lti19BIJzAb+oKqzgEaC031wAk+f9JXAOGAMEC8iNwW3qtAhIv+G0/34zDCoJQ74N+C+YNfSj0ggFaeL9k7gec92n6cl1AJ92G5G7cVG2sFwDnCFiOzF6Z66QESeDm5JgPPnWKqq3T/FvIAT8MH2eWCPqlaqajuwFPhMkGvqqUJEsgE8X/3yY7o/iMgtwOXAV3V43NwyAec/5g2ev/+5wHoRGR3Uqo4rBZaq42Ocn6BPe9A21AL9n8BEERknIlE4A1Z/C3JN3m6kPeRU9W5VzVXVApzfq7dVNehXnKp6CDggIpM9L10IbAliSd32AwtEJM7zZ3ohw2Cwtoe/Abd4nt8CvBLEWo4RkUXAj4ErVLUp2PUAqOpGVR2lqgWev/+lwGzP373h4GXgAgARmQRE4YdVIUMq0D0DL/8KvIHzD+15Vd0c3KqA4xtpXyAixZ7HZcEuapj7HvCMiHwKFAG/CG454PmJ4QVgPbAR599HUG4dF5FngdXAZBEpFZF/AX4JXCQiO3BmbvxymNT1eyARWO75u//IMKlrWOintseB8Z6pjM8Bt/jjJxu79d8YY8JESF2hG2OM6Z8FujHGhAkLdGOMCRMW6MYYEyYs0I0xJkxYoBtjTJiwQDfGmDDx/wMJ1MufQxcNJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAbwyXTWEPo8"
   },
   "source": [
    "Next, let’s build the dictionary to convert the index to word for target and source vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1623400811746,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "8vnbI8JnEQLt"
   },
   "outputs": [],
   "source": [
    "\n",
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcuYggZSEWs6"
   },
   "source": [
    "# Inference\n",
    "Set up the inference for the encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1623400812053,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "TWVMz2MyEY_y"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1623400812054,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "xz20nxZUgSP-",
    "outputId": "853c4ea7-5216-4cfb-b474-748ab4c12817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder_model.save('C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/my_model_encoder.h5')\n",
    "decoder_model.save('C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/my_model_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.saved_model.save(encoder_model, 'C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/encoder_model/encoder_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(encoder_model, 'C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/encoder_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/decoder_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(decoder_model, 'C:/Users/JumpStart/PycharmProjects/DeepLearningInVision-project/decoder_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcRNRzreEhUD"
   },
   "source": [
    "We are defining a function below which is the implementation of the inference process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1623400812056,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "pVE1RJwLErt6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46dvcOEzEwx_"
   },
   "source": [
    "Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1623400812057,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "49faWzq7EzUc"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avTEUggvE2ya"
   },
   "source": [
    "\n",
    "Here are a few summaries generated by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22227,
     "status": "ok",
     "timestamp": 1623400834272,
     "user": {
      "displayName": "Anna Huber",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJz-_SL6vuawkm5ETjJt2j6v0QQ49PXP0aPolLmg=s64",
      "userId": "00525964629377248699"
     },
     "user_tz": -120
    },
    "id": "PIGCALY6E36u",
    "outputId": "f53a3361-52e8-4c89-c47a-8eb7c8ef6a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: great think might even better regular brownies good happy found \n",
      "Original summary: so good \n",
      "Predicted summary:  great brownies\n",
      "\n",
      "\n",
      "Review: candies soft soft pepermint means melt mouth bite break apart bad sad buy another kind soft peppermint next go around \n",
      "Original summary: soft \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: love bob red mill products grains blend ground included multigrain bread without grinding home pantry staple house price fantastic \n",
      "Original summary: makes great multigrain bread \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: think product excellent came quickly used almost buy \n",
      "Original summary: excellent product \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: quality extract unbelievable results great everyone always says something different makes results better \n",
      "Original summary: cake cookies pies \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: recently started baking bread yeast perfect rises consistantly every time held great frozen \n",
      "Original summary: great for bread \n",
      "Predicted summary:  great bread\n",
      "\n",
      "\n",
      "Review: spicy thai beef jerky makes quick high protein snack meals would give five stars tough unchewable pieces every bag tender pieces good \n",
      "Original summary: great stuff \n",
      "Predicted summary:  great jerky\n",
      "\n",
      "\n",
      "Review: ingenious idea taking wine picnics tailgating etc wine pretty good everywhere taken everyone wants get \n",
      "Original summary: best wine for \n",
      "Predicted summary:  wine wine wine wine\n",
      "\n",
      "\n",
      "Review: although flops failed jelly belly standards still taste great get passing grade family enjoyed considerably fun pick different jelly bellys guess flavors looking colors tasting quality still great flops \n",
      "Original summary: jelly flops an in my book \n",
      "Predicted summary:  great jelly\n",
      "\n",
      "\n",
      "Review: even dog cure think could drink read reviews people seem like lot others agree seriously would rather drink cod liver oil \n",
      "Original summary: just awful \n",
      "Predicted summary:  not good\n",
      "\n",
      "\n",
      "Review: gripe come vacuum sealed safety seal think one mess popcorn lid large put jar side popcorn came spilling floor almost every kernel pops overall good product exciting well popcorn get \n",
      "Original summary: very good popcorn \n",
      "Predicted summary:  popcorn\n",
      "\n",
      "\n",
      "Review: love idea pack grab go stay fresh great campfire time perfect size mores stick pack ziploc hershey bar marshmallows ready roast others packs stay fresh ready eat \n",
      "Original summary: yummy and fresh \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: yr old poodle loves love healthy happy win win ask life \n",
      "Original summary: loves the food \n",
      "Predicted summary:  my dog loves these\n",
      "\n",
      "\n",
      "Review: knew something wrong opened bag beans shine smell coffee worst shelf store brand cost thought could never taste bad coffee bought three bags \n",
      "Original summary: worst coffee ever had \n",
      "Predicted summary:  terrible\n",
      "\n",
      "\n",
      "Review: enjoy opportunity purchase smaller bags chips able eat anytime amazon allow us experience enjoy different varities terra chip product \n",
      "Original summary: terra blue potato chips \n",
      "Predicted summary:  great chips\n",
      "\n",
      "\n",
      "Review: sold java city outlets sacramento ca blended ice juice makes wonderful smoothie like acai berry flavor love juice blend \n",
      "Original summary: great smoothie juice \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: live natural organic prone life eating newtons addictive gooey twice filling yum person used eating trans fat loaded cookies give try \n",
      "Original summary: addictive \n",
      "Predicted summary:  yummy\n",
      "\n",
      "\n",
      "Review: mom enjoyed coffee well wanted get even monthly price ridiculous sad \n",
      "Original summary: good flavor \n",
      "Predicted summary:  great coffee but overpriced\n",
      "\n",
      "\n",
      "Review: ordered huge diet still whole case left didnt enjoy taste thats nothing sell product \n",
      "Original summary: ordered for diet \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: get package find expire months ordered enough last months able keep long gives \n",
      "Original summary: not fresh enough for subscribe and save \n",
      "Predicted summary:  expired\n",
      "\n",
      "\n",
      "Review: best apple juice purchased children several adults ask brand juice good \n",
      "Original summary: very good \n",
      "Predicted summary:  juice\n",
      "\n",
      "\n",
      "Review: kitty cat grown quite addicted particular brand flavor cat food eats comes looking suits never sick like ingredients happy \n",
      "Original summary: our kitty loves this \n",
      "Predicted summary:  cat loves it\n",
      "\n",
      "\n",
      "Review: polar kipper snacks excellent buying since price crown prince snacks went good better crown prince lot cheaper tried brands kipper snacks polar snacks good better heights mi \n",
      "Original summary: kipper snacks \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: coffee drinker like coffee light bit sweet hits spot brand coffees tend sugar milk coffee one strong coffee flavor right convenience stores ordering \n",
      "Original summary: love this drink \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: love rub use pork tenderloins charcoal grill fun tongue everyone served asked rub find given many tins away gifts \n",
      "Original summary: fun on the tongue \n",
      "Predicted summary:  great rub\n",
      "\n",
      "\n",
      "Review: enjoyed cereal years unlike many fun cereals lot offer nutrition fiber content often treat cup grams fiber \n",
      "Original summary: great fun cereal \n",
      "Predicted summary:  great cereal\n",
      "\n",
      "\n",
      "Review: one granola bars meets son needs gluten dairy egg soy apple free stand carried around purse always safe snack handy unlike crumble easily met taste test turned plenty ones settled \n",
      "Original summary: on the go snack for highly allergic \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: ordered smoke paprika unfortunately received regular sweet called spoke gentleman promised send smoke paprika apologized mistake made today still received anything heard company disappointed \n",
      "Original summary: very disappointed \n",
      "Predicted summary:  not as good as the pictured\n",
      "\n",
      "\n",
      "Review: delicious snacks addicting totally replace need potato chips salted snacks plus additional benefit helping stay regular cannot go wrong thank nabisco thank amazon \n",
      "Original summary: love them \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: getting cereal subscribe save department really handy get delivery mail every months husband eats brand price would stay \n",
      "Original summary: husband is happy \n",
      "Predicted summary:  great cereal\n",
      "\n",
      "\n",
      "Review: quite simply closest get homemade taste great easy store add spices want flavoring less minutes refried beans side dish use nachos recipes calling ingredient buy regularly \n",
      "Original summary: no canned beans compare \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: love tapioca know previous reviewer meant flavor recipe make another recipe though add end without whipping first \n",
      "Original summary: superb tapioca \n",
      "Predicted summary:  best ever\n",
      "\n",
      "\n",
      "Review: pugs pretty notorious refusing take pills work make want take pills pill time become equivalent treat time easy negative get bit expensive \n",
      "Original summary: works as advertised \n",
      "Predicted summary:  pill pockets\n",
      "\n",
      "\n",
      "Review: great tasting coffee like go caffeine free later evening like hint sweetness hazelnut flavoring coffee enough flavor make oz size without tasting watered \n",
      "Original summary: great tasting after dinner coffee \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: favorite sugar free flavors use make vanilla flavored steamed milk top cinnamon tastes like snicker doodle cookie \n",
      "Original summary: delicious \n",
      "Predicted summary:  love this stuff\n",
      "\n",
      "\n",
      "Review: energy club crispy pumpkin seeds ounce bags favorite pumpkin seeds snack lightly salted crunchy good flavor \n",
      "Original summary: energy club crispy pumpkin seeds ounce bags \n",
      "Predicted summary:  very tasty\n",
      "\n",
      "\n",
      "Review: tried sugar substitutes friend referred agave used anything else since best product use place sugar \n",
      "Original summary: madhava agave nectar is the best \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: searching easy quick mess snacks busy lifestyle despite fact promoted kids convenient snacks adults spoon spill drip yummy \n",
      "Original summary: healthy on the go snack \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: way overpriced received small amount oz ordering product company \n",
      "Original summary: sugar \n",
      "Predicted summary:  rip off\n",
      "\n",
      "\n",
      "Review: vet recommended years ago cat digestive tract size dental floss always got pet smart cheaper amazon delivered right door \n",
      "Original summary: good for protein sensitive cats \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: enjoy kind bars especially non fruit bars agrees stomach sensitivies store bought products important bars satisfies cravings something sweet without making sick good flavor sea salt one different \n",
      "Original summary: excellent snack \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: happy finally found reasonable price since also pack know look time soon product exactly expected phenomenal sushi remember enjoy \n",
      "Original summary: just as expected \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: came across local grocery store grabbed bottle fruit punch tried long tried every flavor mango peach favorite flavor one exceptionally good \n",
      "Original summary: yummy \n",
      "Predicted summary:  great flavor\n",
      "\n",
      "\n",
      "Review: make coffee really love great flavors add scoop equal exchange hot drizzle raw honey make perfect mocha \n",
      "Original summary: mm \n",
      "Predicted summary:  love this coffee\n",
      "\n",
      "\n",
      "Review: product arrived quickly treats fresh definitely order dogs run treats low cal added bonus \n",
      "Original summary: happy dogs \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: love product tasted like banana nut bread good number flavors stuck one either reasonably priced \n",
      "Original summary: so tasty and filling \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: things worse follows sprouts lemon pie anything lemon besides radish disgusting foods stars \n",
      "Original summary: some of the worst stuff on earth \n",
      "Predicted summary:  terrible\n",
      "\n",
      "\n",
      "Review: great product price surprised bottle arrives vacuum seal broken minor leakage happened us couple times stopped us buying \n",
      "Original summary: great product but expect \n",
      "Predicted summary:  great product but overpriced\n",
      "\n",
      "\n",
      "Review: agree positive reviews please confuse taster choice freeze dried product nescafe classic hard understand coffee products come company strange \n",
      "Original summary: mystery coffee marketing \n",
      "Predicted summary:  not good\n",
      "\n",
      "\n",
      "Review: bought dad dementia hoping help even little mom ended also using face cream loves adds cereal every morning \n",
      "Original summary: hoping for great results \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: secret sauce prize winning chili years perfect balance flavor heat tell anyone \n",
      "Original summary: secret sauce \n",
      "Predicted summary:  great sauce\n",
      "\n",
      "\n",
      "Review: good substantial ones bought costco past thought solid middle thse splinter easily \n",
      "Original summary: pretty good \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: son months still one favorite gluten free snacks wish would make puffs gluten free dosen seem mind though \n",
      "Original summary: son loves these \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: keebler olive oil crackers taste ok waste money broken pieces \n",
      "Original summary: crackers \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: used flavors years great product keep awake driving bathroom stops coffee keep bag two car one purse time \n",
      "Original summary: hazelnut coffee flavor \n",
      "Predicted summary:  great flavor\n",
      "\n",
      "\n",
      "Review: brazil nuts fresh tasting part delivery fast rancid nuts tend get price good buy \n",
      "Original summary: good product \n",
      "Predicted summary:  nuts\n",
      "\n",
      "\n",
      "Review: good quick cup coffee slightly different flavor blend quite enough really make huge impact taste \n",
      "Original summary: kona blend \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: keep hand young heart enjoy cup almost every night good taste buy \n",
      "Original summary: the soul \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: using product last weeks drink one breakfast lunch everyday eat normal meal dinner great way loose weight keep energy levels day \n",
      "Original summary: great taste perfect for meal replacement \n",
      "Predicted summary:  great breakfast\n",
      "\n",
      "\n",
      "Review: ordered sent son make homemade ones thinks grandma almost good mine thoroughly enjoyed \n",
      "Original summary: yummy treat for the grandma cookie lovers \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: noodles quick easy perfect busy moms wanting eat dash shopping lunch hour diet eaten cup noodles years best flavor vegetables also great value \n",
      "Original summary: cup noodles maruchan beef flavored \n",
      "Predicted summary:  great for quick lunch\n",
      "\n",
      "\n",
      "Review: pamela awesome makes eat gluten free manageable cookies muffins pancakes crepes yumm easy \n",
      "Original summary: awesome stuff \n",
      "Predicted summary:  pamela baking mix\n",
      "\n",
      "\n",
      "Review: tried lot prepared add water kind foods busy college student far worst \n",
      "Original summary: yuck \n",
      "Predicted summary:  nasty\n",
      "\n",
      "\n",
      "Review: like said hot cocoa excellent first last sip sipping cocoa mean first taste good followed middle taste even better love cocoa \n",
      "Original summary: excellent from first to last sip \n",
      "Predicted summary:  best cocoa ever\n",
      "\n",
      "\n",
      "Review: great beef jerky low salt great flavor plus cheapest jerky amazon love \n",
      "Original summary: awesome \n",
      "Predicted summary:  great jerky\n",
      "\n",
      "\n",
      "Review: think best licorice soft natural fresh tried number one book \n",
      "Original summary: are great \n",
      "Predicted summary:  licorice\n",
      "\n",
      "\n",
      "Review: zipfizz tastes good keeps moving day zipfizz loaded energy great lack required rest night \n",
      "Original summary: great for keeping you on the go \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: great box kinds yummy vitamin infused gummy snacks grape white grape peach strawberry sorts delicious fruit flavors disappointed variety box really big portions great good value purchase \n",
      "Original summary: yummy selection \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: feeding year old female cat blue buffalo salmon flavored thought would try bit normally relatively slow eater gobbled quarter cup minutes tops went crazy best part upset stomach \n",
      "Original summary: our cat loves this stuff \n",
      "Predicted summary:  my cat loves this\n",
      "\n",
      "\n",
      "Review: product good expensive especially feeding family four even treat door family wheat free products less likely buy product \n",
      "Original summary: biscotti \n",
      "Predicted summary:  good product\n",
      "\n",
      "\n",
      "Review: sweet tastes great like nut butter sweetened sugar plus fiber peanut butter great alternative carb counters use place peanut butter everything try see talking \n",
      "Original summary: healthy but delicious \n",
      "Predicted summary:  great taste\n",
      "\n",
      "\n",
      "Review: delicious gingerale without sugars chemicals commercial brands nice balanced flavor ginger really helps stomach \n",
      "Original summary: love it \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: love crystal light tea raspberry favorite flavor agree getting harder find raspberry flavor stores carry little packets instead plastic cups prefer little cups think time stock \n",
      "Original summary: best flavor \n",
      "Predicted summary:  love this tea\n",
      "\n",
      "\n",
      "Review: make overnight slow cooker cups oatmeal cup dried fruit little salt cups water start bedtime ready morning freeze cup bowls oatmeal week \n",
      "Original summary: mm \n",
      "Predicted summary:  great for breakfast\n",
      "\n",
      "\n",
      "Review: display shows spearmint gum also comes peppermint spearmint kind looking anywhere purchase spearmint bulk \n",
      "Original summary: spearmint gum \n",
      "Predicted summary:  not what expected\n",
      "\n",
      "\n",
      "Review: recently tried half caff loved even within hours bedtime problem falling sleep coffee really great taste fan decaff coffees \n",
      "Original summary: just great \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: thirteen years old love texture little awkward going mark considering meant little ones \n",
      "Original summary: yum \n",
      "Predicted summary:  good but not great\n",
      "\n",
      "\n",
      "Review: best oatmeal ever tasty wonderful texture cannot recommend product highly enough \n",
      "Original summary: great oatmeal \n",
      "Predicted summary:  best oatmeal ever\n",
      "\n",
      "\n",
      "Review: tried lots gluten free breads pamela far superior fall apart making sandwich taste like sawdust \n",
      "Original summary: gluten free bread \n",
      "Predicted summary:  best gf bread\n",
      "\n",
      "\n",
      "Review: chicory flavorful perfect roast suitable brewing straight blending ground coffee whichever desire happy jim \n",
      "Original summary: excellent chicory \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: good convenient coffee make use packet cup water little strong use whole packet try like \n",
      "Original summary: starbucks via colombia packets \n",
      "Predicted summary:  good coffee\n",
      "\n",
      "\n",
      "Review: drank blended coffees far best one tasted keep coming \n",
      "Original summary: delicious \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: cat food cats otherwise different tastes love especially older cat picky eater problem stomach upsets throwing like reviewer cat \n",
      "Original summary: all my cats love it \n",
      "Predicted summary:  my cats love it\n",
      "\n",
      "\n",
      "Review: nice coffee chocolately hint would def buy wondeful coffee beautiful aroma \n",
      "Original summary: lovely \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: terrific easy way grow fresh herbs kitchen mess garden growing month ready harvest soon company support superb one seed pod germinate within week replaced \n",
      "Original summary: great product \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted summary:  great product\n",
      "\n",
      "\n",
      "Review: question pickled sausages hearts ingredient freakin disgusting \n",
      "Original summary: yuck \n",
      "Predicted summary:  yuck\n",
      "\n",
      "\n",
      "Review: salty cut equal amount water surprised still plenty flavor \n",
      "Original summary: something new \n",
      "Predicted summary:  too salty\n",
      "\n",
      "\n",
      "Review: chocolate fresh delicious tastes exactly like ones buy europe love bounty love coconuts definitely satisfy cravings buy seller \n",
      "Original summary: yummy \n",
      "Predicted summary:  delicious\n",
      "\n",
      "\n",
      "Review: recently amazing watermelon licorice traveling could find brand online thought would try one flavor good licorice stale think even able eat \n",
      "Original summary: stale \n",
      "Predicted summary:  licorice\n",
      "\n",
      "\n",
      "Review: sorry found taste unpalatable spicy also upset got turkey instead beef ordered \n",
      "Original summary: ordered beef bites got these \n",
      "Predicted summary:  nasty\n",
      "\n",
      "\n",
      "Review: absolutely love flavor son normally eat sweet potato one makes feel good eating healthy veggies fruits junk snacks \n",
      "Original summary: sweet potato apple carrots \n",
      "Predicted summary:  great snack\n",
      "\n",
      "\n",
      "Review: good frozen soup products always quite tasty foods \n",
      "Original summary: soup \n",
      "Predicted summary:  great soup\n",
      "\n",
      "\n",
      "Review: spectacular replacement sugar drinks athletes drinking natural pure healthy know kid drinking oz gatorade day pounds one year smart healthy try switch coconut water \n",
      "Original summary: goodbye gatorade \n",
      "Predicted summary:  best sweetner ever\n",
      "\n",
      "\n",
      "Review: like black licorice treat super alternative chewing gum mints like ease small package small mouth refresher buying larger quantity make easy offer package someone watch smile face \n",
      "Original summary: yes to \n",
      "Predicted summary:  licorice\n",
      "\n",
      "\n",
      "Review: beat previous supplier use long espresso setting make great \n",
      "Original summary: best price \n",
      "Predicted summary:  great espresso\n",
      "\n",
      "\n",
      "Review: horrible ruined whole dinner smelled bad even son take right trash outside \n",
      "Original summary: hated them \n",
      "Predicted summary:  nasty\n",
      "\n",
      "\n",
      "Review: smokehouse chicken kabobs labeled product china unfortunately enough reason feed pet \n",
      "Original summary: made in china \n",
      "Predicted summary:  made in china\n",
      "\n",
      "\n",
      "Review: good value find star along available big box stores altho ok spoiled consider star molina vanilla cannot find around \n",
      "Original summary: good value but we prefer \n",
      "Predicted summary:  good value\n",
      "\n",
      "\n",
      "Review: really care bag coffee pretty nice bag got nice assortment nice price chose crazy cups listings liked picture received happy assortment didnt see anything despite claims title good purchase \n",
      "Original summary: nice assortment \n",
      "Predicted summary:  good selection\n",
      "\n",
      "\n",
      "Review: used use regular sleepytime stopped working use marvelous tastes pretty good \n",
      "Original summary: its the best \n",
      "Predicted summary:  great product\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFIsA0LOFCh6"
   },
   "source": [
    "This is really cool stuff. Even though the actual summary and the summary generated by our model do not match in terms of words, both of them are conveying the same meaning. Our model is able to generate a legible summary based on the context present in the text.\n",
    "\n",
    "This is how we can perform text summarization using deep learning concepts in Python.\n",
    "# How can we Improve the Model’s Performance Even Further?\n",
    "Your learning doesn’t stop here! There’s a lot more you can do to play around and experiment with the model:\n",
    "\n",
    " **increase the training dataset** size and build the model. The generalization capability of a deep learning model enhances with an increase in the training dataset size\n",
    "\n",
    "implementing **Bi-Directional LSTM** which is capable of capturing the context from both the directions and results in a better context vector\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNgVV+N4JGu6dWNrRrww5zL",
   "collapsed_sections": [],
   "name": "Text Summarizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
